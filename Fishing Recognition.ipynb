{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fishing Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "\n",
    "##### Monitor fishing activities from space to detect abnormal use of fishing gear [1]. \n",
    "Method:\n",
    "    1) Train Gaussian Mixture Model for regimes from series of the speed and turning angle computed from the VMS data\n",
    "    2) Apply fitted gear-specific GMMs to extract associated regime related features. (Time spent, mean duration, etc.)\n",
    "    3) Combine with other features; (mean position and sinuosity index) with a suupervised classification framework. - RF and SVM with recoginition rates ~94.59%\n",
    "Notes:\n",
    "- The characteristics of each activity can be expected to vary from one fishing gear type to another.\n",
    "\n",
    "Data:\n",
    "- VMS data, computed speed and turning angle series using first-order finite differences.\n",
    "- Filtered VMS Data:\n",
    "    -Preprocessing\n",
    "    - duplicate data\n",
    "    - acquisition time steps below 120 seconds between two sucessive locations along VMS trajectory\n",
    "    - data associated with a speed five times greater than the trajortory speed (spike)\n",
    "    - low speed segment (<= 0.5 knots) for a time interval greater than six hours. Remove port, break down, etc.\n",
    "\n",
    "Algs:\n",
    "1. Characterize the movement patterns for each fishing gear, unsupervised scheme. Guassian Mixture Models (GMM). Model the join distribution of the speed and the turning angle as a GMM (weighted sum of M Gaussian densities)\n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture4.PNG?raw=true)\n",
    "where x is a 2-dimensional continuous-valued data vector (speed and turning angle). $W_i$ where $i=1,...,M$ are the mixture of weights. $g(x|\\mu _i,\\sum _i)$ , $i=1,...,M$ are Gaussian densities. Each density is a bivariate Gaussian function of the form\n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture5.PNG?raw=true)\n",
    "\n",
    "with mean vector $\\mu _i$ and covariance matrix $\\sum _i$. The mixture weights satisfy the constraint that $\\sum ^M _(i=1) w _i = 1$. Overall the parameters of the GMM are stored in $\\lambda = {w _i , \\mu _i , \\sum _i }, i = 1,...,M$. \n",
    "\n",
    "This is fit to the join distribution of speed and the turning angle. The maximum likelihood inference of GMM parameters $\\lambda$ using iterative expectation-maimization (EM) algorithm. ${x _k}$ is the dataset of speed and turning angle feature vectors, and $Z _k$ the latent variable, which states the component the kth data is associated with. \n",
    "\n",
    "EM Algorithm:\n",
    "Expectation Step: (evaluates the posterior likelihood of the latent variable)\n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture6.PNG?raw=true)\n",
    "\n",
    "Maximization Step, updates the model parameter $\\lambda$ given the posterior likelihoods;\n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture7.PNG?raw=true)\n",
    "\n",
    "##### Automatic Recognition of the Fishing Gear\n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture8.PNG?raw=true)\n",
    "1. Unsupervised GMM-based analysis of VMS data\n",
    "2. Feature Extraction of Vectors: Global characterization of any trajectory. For a given vessel, specific VMS datasets. Time spent in each regieme, also calcualte the mean duration of each regime period from the regimes identified.\n",
    "3. Supervised learning of a recognition model. After feature extraction, perform classification. Generated features below. \n",
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture9.PNG?raw=true)\n",
    "\n",
    "Used RF and SVM, with 20 fold cross-validation procedure (found results were the same). \n",
    "\n",
    "#### Fishing Pattern dection with AIS and ML [2].\n",
    "Three methods, one for each vessel type:\n",
    "1) Trawlers [84% Accuracy]: Hidden Markov Model using vessel speed as observation variable\n",
    "-Drag nets behind vessel either sea floor (bottom trawling) or water column (pelagic or midwater trawling)\n",
    "- Length: Minutes - Hours, usually 3-5 hours. Speed: 2.5-5.5 knots\n",
    "2) LongLiners [83% Accuracy]: Data Mining apporach using algorithm inspired from studies on animal movement.\n",
    "- Fishing lines up to 100 km in length.\n",
    "- Lines deployed at various depths, use a speed slightly slower than steaming speed. Then the vessel drifts or sets more lines elsewhere.  Est Time. ~6 hours. Classification used for identification of longline setes comprise spatial-temporal movement patters in a very restricted area. \n",
    "3) Purse Senier [97% Accuracy]: Multi-layered filtering strategy based on vessel speed and operation time.\n",
    "- Long nets deployed hanging vertically from floats around schooling fish near the surface. Done at high speeds ~10 knots. Drifting with the net attached, they collect the fish. Duration varys from 1 to serveral hours. \n",
    "    \n",
    "    Data & Methods\n",
    "1. For all points to imporve fishing activity prediction, calculated whether it occurred during the night or day. (used R package solaR)\n",
    "2. Established a 10 km boundary around shorelines. Required calculated of the Haversine distance between each vessel track point and all the points in the shoreline data (see dataset for this @ Natural Earth in the paper) used code found here for parallel speed up. http://stackoverflow.com/questions/27697504/ocean-latitude-longitude-point-distance-from-shore\n",
    "    \n",
    "#### Mapping EU fishing activities using ship tracking data (Trawlers Only)[3]\n",
    "\n",
    "1. Data Cleaning: Position and speed data cleaned for errors. Data decimated to an inteval of 5 minutes between observations. \n",
    "2. Fishing Behaviour Identification: the points corresponding to fishing behaviour (see Algorithm 1) are extracted based on the assumption that there is a separation of fishing activities with a steaming speed that is relatively high with respect to fishing speed. The resulting speed profiles, after excluding the zero-velocity points that relate to messages sent when the vessel is likely to be in a port, show a bi-modal distribution.\n",
    "\n",
    "![Trawler Speed Profile](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture.PNG?raw=true)\n",
    "\n",
    "Depending on vessel size, area, fishing gear and many other factors, fishing vessels exhibit specific mean and standard deviation values of the speed bi-modal distributions. For this reason, the identification of fishing behaviour has to be implemented for each individual vessel (Natale et al., 2015). Using a Gaussian Mixture Model (GMM), an unsupervised classification method, we isolated the two main activities distributions and obtained the component parameters. Fishing speed confidence intervals were built for each vessel using the first component mean and standard deviation.\n",
    "\n",
    "![Trawler Speed Profile](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture2.PNG?raw=true)\n",
    "\n",
    "4. Accuracy and validation \n",
    "The aggregated fishing intensity value for a specific cell is subject to the completeness of information that can be collected in that area. In our case, since the reception of AIS is related to the radio propagation of the messages transmitted by the vessel, such completeness is mainly linked to the distance to the closest AIS receiving station. Nevertheless, the propagation of AIS messages is also influenced by the atmospheric conditions in the area and significantly varies accordingly.  \n",
    "\n",
    "#### Mapping Fishing Effor Through AIS Data[4].\n",
    "\n",
    "Data and Methods:\n",
    "\n",
    "1. Computed the trajectories from AIS observations. Ratio between AIS position and the trajectory interpolated points was used to estimate the AIS spatial coverage capabilities\n",
    "\n",
    "2. Methodology used for the identification of fishing activity is based on assuming a fishing behaviour highly dependent and characterised by speed. Detecting changes and frequency of speed will help identifying which part of the vessel track can be considered as fishing and which not. Among the different fishing behaviours, those vessels employing amobile gear are characterized by a clear speed fingerprint. Hence we willexpect better parameters estimates for trawlers\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "1) Only messages with a speed greater than 0.5 knots (0.257 m/s). Usually a large portion of low speed messages are at the port. \n",
    "2) Some vessels do not systematically use the AIS, therefore these were dropped from the dataset.\n",
    "\n",
    "3) A final cleaning filter consisted in omitting outliers and probable errors represented by messages whose speed was higher than the upper quartile plus 1.5 times the interquartile range. \n",
    "\n",
    "4) Data preparation process we investigated the distribution of every vessel speed profile by creating histograms of the speed. The speed histograms of most vessels showed a bimodal distribution, with the two modes corresponding to steaming (high speed) and fishing (lowspeed) behaviours.The bimodal distribution of speeds can be interpreted as the mixture of two Gaussian curves. \n",
    "    \n",
    "![Speed Profile](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture3.PNG?raw=true)\n",
    "\n",
    "\n",
    "5) Using expectation maximization (EM) alg, possible to estimate the two distributions' parameters and to assign the observations to a particular model component. Distribution of speed profiles for every vessel was analysed (R) using mixtools library and the fuction NormalmixEMcomp2 designed for Gaussian mixtures. For every vessel, a vector containing the parameters of the two Gaussian components: the fishing speed and the steaming speed distributions. For the purpose of the analysis we considered only the fishing speed distribution, i.e. the first mode,and its corresponding parameters. Speed confidence intervasl related to fishing activites for a specific vessel, they defined it as +/- 1.5 std. from the first mode. Note, this is just for the trawl fishing type. \n",
    "\n",
    "6) Performance of the algorithm changed between different gears and individualvessels. In particular the performance resulted higher for otter trawler, bottom andmid-water, pairtrawler, purse seiner and Danishseiner andlower in the case of gillnetter, long-linerand fishing pots. \n",
    "\n",
    "7) Vessels with fixed gear for examples, such aspots, have different speed profiles, characterized by the presence of messages with speed of values zero (messages that have been omitted in our model). Further improvements of themodel will include zero speed messages that are not located in the port and also considering non Gaussian mixture morel components. \n",
    "\n",
    "8) Regardless of the shape of the distributions it is natural to expect that fishing corresponds to the speed with the highest frequency in the speed profiles (first mode) considering that fishermen would tend over the long period to optimise the time spent at sea and the fuel consumption,concentrating great part of their time spent at sea in the fishing activity rather than at steaming. Starting from this consideration a direction which would merit more investigation in future research is to use the analysis of speed profiles as indicator offishing efficiency. A higher frequency of AIS messagesfor steaming rather than fishing speed is indicating that a vessel is travelling for longer periods to reach the fishing grounds and has therefore higher cost and fuel consumption for the same amount of effective fishing effort.\n",
    "    \n",
    "Sources:\n",
    "1. Marzuki, Marza Ihsan, Rene Garello, Ronan Fablet, Vincent Kerbaol, and Philippe Gaspar. \"Fishing Gear Recognition from VMS Data to Identify Illegal Fishing Activities in Indonesia.\" OCEANS 2015 (2015): n. pag. Web.\n",
    "2. Souza, Erico N. De, Kristina Boerder, Stan Matwin, and Boris Worm. \"Improving Fishing Pattern Detection from Satellite AIS Using Data Mining and Machine Learning.\" PLOS ONE 11.7 (2016): n. pag. Web.\n",
    "3. Vespe, Michele, Maurizio Gibin, Alfredo Alessandrini, Fabrizio Natale, Fabio Mazzarella, and Giacomo C. Osio. \"Mapping EU Fishing Activities Using Ship Tracking Data.\" Journal of Maps (2016): 1-6. Web.\n",
    "4. Natale, Fabrizio, Maurizio Gibin, Alfredo Alessandrini, Michele Vespe, and Anton Paulrud. \"Mapping Fishing Effort through AIS Data.\" PLOS ONE PLoS ONE 10.6 (2015): n. pag. Web.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My approach\n",
    "\n",
    "Considerations:\n",
    "    Ensure that the Position and speed data are selected and cleaned in case of errors.\n",
    "    May need to split into consistent points, eg. 5 minute spans\n",
    "    Different types of vessels fish differently (eg. Trawlers, Longliners, and Purse Senier)\n",
    "    Different types of vessels have specific behaviour dependant on vessel size, area, fishing gear, etc. You can generate fishing speed confidence intervals to detect behaviour with 95%+ accuracy\n",
    "    Loss of signal, may have areas of weak signal coverage. \n",
    "\n",
    "Data Cleaning:\n",
    "1. Ensure Checksum for All Messages, in new Column, 1 for True, 0 for False (eg. Failed) Drop failing checksums. \n",
    "2. Convert each AIS\n",
    "3. Remove:\n",
    "    - duplicate data\n",
    "    - acquisition time steps below 120 seconds between two sucessive locations along trajectory\n",
    "    - data associated with a speed five times greater than the trajortory speed (spike)\n",
    "    - low speed segment (<= 0.5 knots) for a time interval greater than six hours. Remove port, break down, etc.\n",
    "\n",
    "4. Established a 10 km boundary around shorelines. Required calculated of the Haversine distance between each vessel track point and all the points in the shoreline data (see dataset for this @ Natural Earth in the paper) used code found here for parallel speed up. http://stackoverflow.com/questions/27697504/ocean-latitude-longitude-point-distance-from-shore. (Do not include those with <10 km distance in calculation)\n",
    "\n",
    "Method:\n",
    "1. Train a Guassian Mixture Model for unsupervised identification of relevent regimes from the series of the speed and turning angle from the data. (May need to identify types of fishing gear or just identify different clusters)\n",
    "2. Apply fitted gear specific GMMs to extract some associated regime related features. (Time spent in each regime, mean duration of each regime period, etc.)\n",
    "3. Generate additional features that may be useful. Day/Night,Sinuosity Index, STD of GPS positions, mean GPS position, STD of the mean of each regieme, distance from shore?\n",
    "4. Train an RF, SVM, xgboost model. Compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "import operator\n",
    "from functools import reduce\n",
    "import ais\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('testing_data.csv')\n",
    "train_df = pd.read_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!AIVDM,1,1,,B,35NJH:POhiD:=RpO<EFFbUpB0000,0*19'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['RAW_MESSAGE'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Checksum and message length.\n",
    "def CheckSum(sentence):\n",
    "    checksum = 0\n",
    "    nmeadata,cksum = sentence.split('*')    \n",
    "    for i in range(1,len(nmeadata)):\n",
    "        checksum = checksum ^ ord(nmeadata[i])\n",
    "    checksum = checksum & 0xFF    \n",
    "    cksum = -1\n",
    "    try:\n",
    "        i = sentence.index( '*' )\n",
    "        cksum = int(sentence[i+1:i+3], 16)\n",
    "\n",
    "        if cksum == checksum:\n",
    "            return (True)\n",
    "    except:\n",
    "        pass\n",
    "    return (False)\n",
    "\n",
    "def countlen(sentence):\n",
    "    nmeadata,cksum = sentence.split('*') \n",
    "    return len(nmeadata)\n",
    "train_df['Checksum'] = train_df['RAW_MESSAGE'].apply(CheckSum) #Some give error, probly can get away with a try except\n",
    "test_df['Checksum'] = test_df['RAW_MESSAGE'].apply(CheckSum)\n",
    "\n",
    "train_df['Length'] = train_df['RAW_MESSAGE'].apply(countlen) #These appear to not matter.\n",
    "test_df['Length'] = test_df['RAW_MESSAGE'].apply(countlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AIS Converter\n",
    "# need to install via pip install libais\n",
    "test_raw_message,train_raw_message = pd.DataFrame(),pd.DataFrame()\n",
    "test_raw_message['RAW_MESSAGE'] = test_df['RAW_MESSAGE']\n",
    "train_raw_message['RAW_MESSAGE'] = train_df['RAW_MESSAGE']\n",
    "\n",
    "#Field 1, !AIVDM, identifies this as an AIVDM packet.\n",
    "#Field 2 count of fragments in the currently accumulating message.\n",
    "#Field 3 fragment number of this sentence. It will be one-based. A sentence with a fragment count of 1 and a fragment number of 1 is complete in itself.\n",
    "#Field 4 sequential message ID for multi-sentence messages.\n",
    "#Field 5 radio channel code. AIS uses the high side of the duplex from two VHF radio channels: AIS Channel A is 161.975Mhz (87B); AIS Channel B is 162.025Mhz (88B). In the wild, channel codes 1 and 2 may also be encountered; the standards do not prescribe an interpretation of these but it’s obvious enough.\n",
    "#Field 6 data payload.\n",
    "#Field 7 Number of fill bits requires to pad the data payload to a 6 bit boundary, ranging from 0 to 5. Equivalently, subtracting 5 from this tells how many least significant bits of the last 6-bit nibble in the data payload should be ignored. Note that this pad byte has a tricky interaction with the <[ITU-1371]> requirement for byte alignment in over-the-air AIS messages; see the detailed discussion of message lengths and alignment in a later section.\n",
    "\n",
    "splits = lambda x: pd.Series([i for i in x.split(',')])\n",
    "\n",
    "s = train_raw_message['RAW_MESSAGE'].apply(splits)\n",
    "train_raw_message = train_raw_message.join(s)\n",
    "\n",
    "s = test_raw_message['RAW_MESSAGE'].apply(splits)\n",
    "test_raw_message = test_raw_message.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_raw_message.columns = ['RAW_MESSAGE','F1','F2','F3','F4','F5','F6','F7']\n",
    "train_raw_message.columns = ['RAW_MESSAGE','F1','F2','F3','F4','F5','F6','F7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def payload(encoded):\n",
    "    try:\n",
    "        return ais.decode(encoded, 0)\n",
    "    except:\n",
    "        v = {u'cog': np.nan}\n",
    "        return v\n",
    "train_raw_message['Dict']=train_raw_message['F6'].apply(payload)\n",
    "test_raw_message['Dict']=test_raw_message['F6'].apply(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ast\n",
    "\n",
    "train_raw_message = train_raw_message.join(pd.DataFrame(train_raw_message[\"Dict\"].to_dict()).T)\n",
    "test_raw_message = test_raw_message.join(pd.DataFrame(test_raw_message[\"Dict\"].to_dict()).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_raw_message['FISHING_STATUS'] = train_df['FISHING_STATUS']\n",
    "train_raw_message['TIMESTAMP'] = train_df['TIMESTAMP']\n",
    "test_raw_message['TIMESTAMP'] = test_df['TIMESTAMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sort by MMSI and the TIMESTAMP\n",
    "test_raw_message.sort_index(by=['mmsi', 'TIMESTAMP'], ascending=[True, False], inplace=True)\n",
    "train_raw_message.sort_index(by=['mmsi', 'TIMESTAMP'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAW_MESSAGE</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>Dict</th>\n",
       "      <th>assigned_mode</th>\n",
       "      <th>...</th>\n",
       "      <th>true_heading</th>\n",
       "      <th>type_and_cargo</th>\n",
       "      <th>unit_flag</th>\n",
       "      <th>utc_hour</th>\n",
       "      <th>utc_min</th>\n",
       "      <th>utc_spare</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>FISHING_STATUS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!AIVDM,1,1,,B,35NJH:POhiD:=RpO&lt;EFFbUpB0000,0*19</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>35NJH:POhiD:=RpO&lt;EFFbUpB0000</td>\n",
       "      <td>0*19</td>\n",
       "      <td>{u'slot_increment': 0, u'sync_state': 0, u'tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.541</td>\n",
       "      <td>54.5132</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1438000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!AIVDM,1,1,,A,35Mqsk0016l4N:tOK2OMl0102000,0*30</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>35Mqsk0016l4N:tOK2OMl0102000</td>\n",
       "      <td>0*30</td>\n",
       "      <td>{u'slot_increment': 0, u'sync_state': 0, u'tru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-166.795</td>\n",
       "      <td>54.9148</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1437216632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!AIVDM,1,1,,B,16LhT:0021l43PvOai2VhmGT00T2,0*75</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>16LhT:0021l43PvOai2VhmGT00T2</td>\n",
       "      <td>0*75</td>\n",
       "      <td>{u'slot_timeout': 0, u'sync_state': 0, u'true_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-166.886</td>\n",
       "      <td>55.3169</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1436946041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!AIVDM,1,1,,A,14QGmR0OiPl9KQHO5=3hH0@B0H52,0*52</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>14QGmR0OiPl9KQHO5=3hH0@B0H52</td>\n",
       "      <td>0*52</td>\n",
       "      <td>{u'slot_timeout': 6, u'sync_state': 0, u'true_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.712</td>\n",
       "      <td>54.3185</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1437548828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!AIVDM,1,1,,A,15NC@20P@Sl:`aFOJocCO37l0`Rf,0*36</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>15NC@20P@Sl:`aFOJocCO37l0`Rf</td>\n",
       "      <td>0*36</td>\n",
       "      <td>{u'slot_timeout': 2, u'sync_state': 1, u'true_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.449</td>\n",
       "      <td>54.9102</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>1436784960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       RAW_MESSAGE      F1 F2 F3 F4 F5  \\\n",
       "0  !AIVDM,1,1,,B,35NJH:POhiD:=RpO<EFFbUpB0000,0*19  !AIVDM  1  1     B   \n",
       "1  !AIVDM,1,1,,A,35Mqsk0016l4N:tOK2OMl0102000,0*30  !AIVDM  1  1     A   \n",
       "2  !AIVDM,1,1,,B,16LhT:0021l43PvOai2VhmGT00T2,0*75  !AIVDM  1  1     B   \n",
       "3  !AIVDM,1,1,,A,14QGmR0OiPl9KQHO5=3hH0@B0H52,0*52  !AIVDM  1  1     A   \n",
       "4  !AIVDM,1,1,,A,15NC@20P@Sl:`aFOJocCO37l0`Rf,0*36  !AIVDM  1  1     A   \n",
       "\n",
       "                             F6    F7  \\\n",
       "0  35NJH:POhiD:=RpO<EFFbUpB0000  0*19   \n",
       "1  35Mqsk0016l4N:tOK2OMl0102000  0*30   \n",
       "2  16LhT:0021l43PvOai2VhmGT00T2  0*75   \n",
       "3  14QGmR0OiPl9KQHO5=3hH0@B0H52  0*52   \n",
       "4  15NC@20P@Sl:`aFOJocCO37l0`Rf  0*36   \n",
       "\n",
       "                                                Dict assigned_mode  \\\n",
       "0  {u'slot_increment': 0, u'sync_state': 0, u'tru...           NaN   \n",
       "1  {u'slot_increment': 0, u'sync_state': 0, u'tru...           NaN   \n",
       "2  {u'slot_timeout': 0, u'sync_state': 0, u'true_...           NaN   \n",
       "3  {u'slot_timeout': 6, u'sync_state': 0, u'true_...           NaN   \n",
       "4  {u'slot_timeout': 2, u'sync_state': 1, u'true_...           NaN   \n",
       "\n",
       "      ...     true_heading type_and_cargo unit_flag utc_hour utc_min  \\\n",
       "0     ...              188            NaN       NaN      NaN     NaN   \n",
       "1     ...                0            NaN       NaN      NaN     NaN   \n",
       "2     ...              171            NaN       NaN      NaN     NaN   \n",
       "3     ...                8            NaN       NaN      NaN     NaN   \n",
       "4     ...               99            NaN       NaN      NaN     NaN   \n",
       "\n",
       "  utc_spare        x        y FISHING_STATUS   TIMESTAMP  \n",
       "0       NaN -165.541  54.5132        Unknown  1438000328  \n",
       "1       NaN -166.795  54.9148    Not Fishing  1437216632  \n",
       "2       NaN -166.886  55.3169    Not Fishing  1436946041  \n",
       "3       NaN -165.712  54.3185    Not Fishing  1437548828  \n",
       "4       NaN -165.449  54.9102        Fishing  1436784960  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_raw_message.reset_index(inplace=True)\n",
    "train_raw_message.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>RAW_MESSAGE</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>Dict</th>\n",
       "      <th>...</th>\n",
       "      <th>true_heading</th>\n",
       "      <th>type_and_cargo</th>\n",
       "      <th>unit_flag</th>\n",
       "      <th>utc_hour</th>\n",
       "      <th>utc_min</th>\n",
       "      <th>utc_spare</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>FISHING_STATUS</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>!AIVDM,1,1,,B,35NJH:POhiD:=RpO&lt;EFFbUpB0000,0*19</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>35NJH:POhiD:=RpO&lt;EFFbUpB0000</td>\n",
       "      <td>0*19</td>\n",
       "      <td>{u'slot_increment': 0, u'sync_state': 0, u'tru...</td>\n",
       "      <td>...</td>\n",
       "      <td>188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.541</td>\n",
       "      <td>54.5132</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1438000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!AIVDM,1,1,,A,35Mqsk0016l4N:tOK2OMl0102000,0*30</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>35Mqsk0016l4N:tOK2OMl0102000</td>\n",
       "      <td>0*30</td>\n",
       "      <td>{u'slot_increment': 0, u'sync_state': 0, u'tru...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-166.795</td>\n",
       "      <td>54.9148</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1437216632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>!AIVDM,1,1,,B,16LhT:0021l43PvOai2VhmGT00T2,0*75</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>16LhT:0021l43PvOai2VhmGT00T2</td>\n",
       "      <td>0*75</td>\n",
       "      <td>{u'slot_timeout': 0, u'sync_state': 0, u'true_...</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-166.886</td>\n",
       "      <td>55.3169</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1436946041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>!AIVDM,1,1,,A,14QGmR0OiPl9KQHO5=3hH0@B0H52,0*52</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>14QGmR0OiPl9KQHO5=3hH0@B0H52</td>\n",
       "      <td>0*52</td>\n",
       "      <td>{u'slot_timeout': 6, u'sync_state': 0, u'true_...</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.712</td>\n",
       "      <td>54.3185</td>\n",
       "      <td>Not Fishing</td>\n",
       "      <td>1437548828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>!AIVDM,1,1,,A,15NC@20P@Sl:`aFOJocCO37l0`Rf,0*36</td>\n",
       "      <td>!AIVDM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "      <td>15NC@20P@Sl:`aFOJocCO37l0`Rf</td>\n",
       "      <td>0*36</td>\n",
       "      <td>{u'slot_timeout': 2, u'sync_state': 1, u'true_...</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-165.449</td>\n",
       "      <td>54.9102</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>1436784960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                      RAW_MESSAGE      F1 F2 F3 F4 F5  \\\n",
       "0      0  !AIVDM,1,1,,B,35NJH:POhiD:=RpO<EFFbUpB0000,0*19  !AIVDM  1  1     B   \n",
       "1      1  !AIVDM,1,1,,A,35Mqsk0016l4N:tOK2OMl0102000,0*30  !AIVDM  1  1     A   \n",
       "2      2  !AIVDM,1,1,,B,16LhT:0021l43PvOai2VhmGT00T2,0*75  !AIVDM  1  1     B   \n",
       "3      3  !AIVDM,1,1,,A,14QGmR0OiPl9KQHO5=3hH0@B0H52,0*52  !AIVDM  1  1     A   \n",
       "4      4  !AIVDM,1,1,,A,15NC@20P@Sl:`aFOJocCO37l0`Rf,0*36  !AIVDM  1  1     A   \n",
       "\n",
       "                             F6    F7  \\\n",
       "0  35NJH:POhiD:=RpO<EFFbUpB0000  0*19   \n",
       "1  35Mqsk0016l4N:tOK2OMl0102000  0*30   \n",
       "2  16LhT:0021l43PvOai2VhmGT00T2  0*75   \n",
       "3  14QGmR0OiPl9KQHO5=3hH0@B0H52  0*52   \n",
       "4  15NC@20P@Sl:`aFOJocCO37l0`Rf  0*36   \n",
       "\n",
       "                                                Dict     ...     true_heading  \\\n",
       "0  {u'slot_increment': 0, u'sync_state': 0, u'tru...     ...              188   \n",
       "1  {u'slot_increment': 0, u'sync_state': 0, u'tru...     ...                0   \n",
       "2  {u'slot_timeout': 0, u'sync_state': 0, u'true_...     ...              171   \n",
       "3  {u'slot_timeout': 6, u'sync_state': 0, u'true_...     ...                8   \n",
       "4  {u'slot_timeout': 2, u'sync_state': 1, u'true_...     ...               99   \n",
       "\n",
       "  type_and_cargo unit_flag utc_hour utc_min utc_spare        x        y  \\\n",
       "0            NaN       NaN      NaN     NaN       NaN -165.541  54.5132   \n",
       "1            NaN       NaN      NaN     NaN       NaN -166.795  54.9148   \n",
       "2            NaN       NaN      NaN     NaN       NaN -166.886  55.3169   \n",
       "3            NaN       NaN      NaN     NaN       NaN -165.712  54.3185   \n",
       "4            NaN       NaN      NaN     NaN       NaN -165.449  54.9102   \n",
       "\n",
       "  FISHING_STATUS   TIMESTAMP  \n",
       "0        Unknown  1438000328  \n",
       "1    Not Fishing  1437216632  \n",
       "2    Not Fishing  1436946041  \n",
       "3    Not Fishing  1437548828  \n",
       "4        Fishing  1436784960  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Haversine Between Two Points, get the distance\n",
    "def haversine(x):#lon1, lat1, lon2, lat2):\n",
    "    # decimal degrees to radian\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [x['x1'], x['y1'], x['x2'], x['y2']])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers\n",
    "    return c * r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mmsi_test = test_raw_message['mmsi'].drop_duplicates().tolist()\n",
    "mmsi_train = train_raw_message['mmsi'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compute the Haversine (km), Time Step, Velocity, Acceleration (Del v/ Del t)\n",
    "\n",
    "def compute_HTVA(mmsi_list,raw_message):\n",
    "    raw_message['Haversine'],raw_message['TimeStep'],raw_message['Velocity'],raw_message['Acceleration'] = 0,0,0,0\n",
    "    for mmsi in mmsi_list:\n",
    "        #Find number of entries\n",
    "        entries = raw_message[raw_message['mmsi'] == mmsi]\n",
    "        entries['x'] = entries['x'].astype(float)\n",
    "        entries['y'] = entries['y'].astype(float)\n",
    "        \n",
    "        entries = entries.join(entries['x'].shift(), lsuffix='1', rsuffix='2')\n",
    "        entries = entries.join(entries['y'].shift(), lsuffix='1', rsuffix='2')\n",
    "        \n",
    "        # Where x1 == x2, y1 == y2,  \n",
    "        entries['TimeStep'] = entries['TIMESTAMP'].shift() - entries['TIMESTAMP']\n",
    "        entries = entries[entries.TimeStep != 0]\n",
    "        entries['Haversine'] = entries.apply(haversine, axis=1)\n",
    "        entries['Velocity'] = entries['Haversine'] / entries['TimeStep']\n",
    "        entries['Acceleration'] = (entries['Velocity'].shift() - entries['Velocity'])/(entries['TimeStep'].shift() - entries['TimeStep'])\n",
    "        \n",
    "        raw_message.ix[raw_message['mmsi'] == mmsi, 'Haversine'] = entries['Haversine']\n",
    "        raw_message.ix[raw_message['mmsi'] == mmsi, 'TimeStep'] = entries['TimeStep']\n",
    "        raw_message.ix[raw_message['mmsi'] == mmsi, 'Velocity'] = entries['Velocity']\n",
    "        raw_message.ix[raw_message['mmsi'] == mmsi, 'Acceleration'] = entries['Acceleration']\n",
    "\n",
    "    return raw_message\n",
    "\n",
    "train_raw_message = compute_HTVA(mmsi_train,train_raw_message)\n",
    "test_raw_message = compute_HTVA(mmsi_test,test_raw_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Distance to Coast For Each Point\n",
    "#Data Source: \n",
    "#NASA Goddard Space Flight Center, Ocean Ecology Laboratory, Ocean Biology Processing Group; (2009): Distance to the Nearest Coast Ocean, NASA OB.DAAC. http://oceancolor.gsfc.nasa.gov/cms/DOCS/DistFromCoast. Accessed on 2016/09/08.\n",
    "# [longitude latitude distance]\n",
    "\n",
    "NASA_DNS = pd.read_csv('dist2coast.txt', sep='\t', header = None)\n",
    "NASA_DNS.columns = [\"longitude\", \"latitude\", \"distance\"]\n",
    "NASA_DNS = NASA_DNS.astype(float)\n",
    "NASA_DNS.sort_index(by=['longitude', 'latitude'], ascending=[True, True], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def binary_search(a, x, lo=0, hi=None):   # can't use a to specify default for hi\n",
    "    hi = hi if hi is not None else len(a) # hi defaults to len(a)   \n",
    "    pos = bisect_left(a,x,lo,hi)          # find insertion position\n",
    "    return (pos) # don't walk off the end\n",
    "\n",
    "#Now find the distance by\n",
    "#1 Find longitude,#2 Find latitude\n",
    "def getDistance(x):\n",
    "    try:\n",
    "        first_left=binary_search(NASA_DNS['longitude'].values, x['x'])\n",
    "        i = 0\n",
    "        for each in NASA_DNS['longitude'].iloc[first_left:].values:\n",
    "            i+= 1\n",
    "            if .1 < np.fabs(x['x'] - each):\n",
    "                break\n",
    "        return NASA_DNS['distance'].iloc[first_left+binary_search(NASA_DNS['latitude'].iloc[first_left:first_left+i].values, x['y'])]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "#Calculate Distances\n",
    "train_raw_message['ShorelineDistance'] = train_raw_message.apply(getDistance,axis=1)\n",
    "test_raw_message['ShorelineDistance'] = test_raw_message.apply(getDistance,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate Distances\n",
    "train_raw_message['ShorelineDistance'] = train_raw_message.apply(getDistance,axis=1)\n",
    "test_raw_message['ShorelineDistance'] = test_raw_message.apply(getDistance,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Checkpoint, pickleing the data to each. \n",
    "# Save: a.to_pickle('my_file.pkl')\n",
    "# Load b = pd.read_pickle('my_file.pkl')\n",
    "\n",
    "# train_raw_message.to_pickle('train_raw_message.pkl')\n",
    "# train_raw_message.to_pickle('train_raw_message-2.pkl')\n",
    "# test_raw_message.to_pickle('test_raw_message.pkl')\n",
    "\n",
    "# train_df.to_pickle('train_df.pkl')\n",
    "# test_df.to_pickle('test_df.pkl')\n",
    "\n",
    "# NASA_DNS.to_pickle('NASA_DNS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the pickles\n",
    "\n",
    "# train_raw_message = pd.read_pickle('train_raw_message-2.pkl')\n",
    "# NASA_DNS = pd.read_pickle('NASA_DNS.pkl')\n",
    "# test_raw_message = pd.read_pickle('test_raw_message-2.pkl')\n",
    "# train_df = pd.read_pickle('train_df.pkl')\n",
    "# test_df = pd.read_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            u'index',       u'RAW_MESSAGE',                u'F1',\n",
       "                      u'F2',                u'F3',                u'F4',\n",
       "                      u'F5',                u'F6',                u'F7',\n",
       "                    u'Dict',     u'assigned_mode',         u'band_flag',\n",
       "                     u'cog', u'commstate_cs_fill',    u'commstate_flag',\n",
       "                   u'dim_a',             u'dim_b',             u'dim_c',\n",
       "                   u'dim_d',      u'display_flag',          u'dsc_flag',\n",
       "                     u'dte',          u'fix_type',              u'gnss',\n",
       "                      u'id',         u'keep_flag',          u'm22_flag',\n",
       "                    u'mmsi',         u'mode_flag',              u'name',\n",
       "              u'nav_status', u'position_accuracy',              u'raim',\n",
       "       u'received_stations',  u'repeat_indicator',               u'rot',\n",
       "          u'rot_over_range',    u'slot_increment',       u'slot_number',\n",
       "             u'slot_offset',      u'slot_timeout', u'slots_to_allocate',\n",
       "                     u'sog',             u'spare',            u'spare2',\n",
       "                  u'spare3', u'special_manoeuvre',        u'sync_state',\n",
       "               u'timestamp',      u'true_heading',    u'type_and_cargo',\n",
       "               u'unit_flag',          u'utc_hour',           u'utc_min',\n",
       "               u'utc_spare',                 u'x',                 u'y',\n",
       "               u'TIMESTAMP',         u'Haversine',          u'TimeStep',\n",
       "                u'Velocity',      u'Acceleration', u'ShorelineDistance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Data\n",
    "# train_raw_message = pd.read_pickle('train_raw_message-2.pkl')\n",
    "test_raw_message = pd.read_pickle('test_raw_message-2.pkl')\n",
    "test_raw_message.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_raw_message.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Prep Data for GMM\n",
    "#Column To Mark Data Considered Bad\n",
    "train_raw_message['BadData'],test_raw_message['BadData'],train_raw_message['Duplicate'],test_raw_message['Duplicate'] = 0,0,0,0\n",
    "\n",
    "# Remove duplicates, Spikes in speed, extra columns\n",
    "\n",
    "#Removes Dups\n",
    "train_raw_message['BadData'][train_raw_message['TimeStep'].isnull()] = 1\n",
    "test_raw_message['BadData'][test_raw_message['TimeStep'].isnull()] = 1\n",
    "\n",
    "train_raw_message['Duplicate'][train_raw_message['TimeStep'].isnull()] = 1\n",
    "test_raw_message['Duplicate'][test_raw_message['TimeStep'].isnull()] = 1\n",
    "\n",
    "#Mark time steps greater than 120 seconds, like in paper, usually first values in series.\n",
    "#Changed to greater than one hour\n",
    "train_raw_message['BadData'][train_raw_message['TimeStep'] > 3600] = 1\n",
    "test_raw_message['BadData'][test_raw_message['TimeStep'] > 3600] = 1\n",
    "\n",
    "#Remove Speeds 5 times Trajectory Speed\n",
    "train_raw_message['BadData'][(5*train_raw_message['Velocity'].shift().abs() < train_raw_message['Velocity'].abs()) & (train_raw_message['mmsi'].shift() == train_raw_message['mmsi'])] = 1\n",
    "test_raw_message['BadData'][(5*test_raw_message['Velocity'].shift().abs() < test_raw_message['Velocity'].abs()) & (test_raw_message['mmsi'].shift() == test_raw_message['mmsi'])] = 1\n",
    "\n",
    "# About 50% of the data is for time stamps > 120. LOL. ~ 55 minutes mean.\n",
    "#      25% 53\n",
    "#      50% 200\n",
    "#      75% 496\n",
    "# Removing speeds 5x adds 66% so play with this value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turning Angle (radians). Can ignore effects from curvature of earth.\n",
    "def turning_angle(x):\n",
    "    try:\n",
    "        p1x,p1y,p2x,p2y,p3x,p3y = x['x23'],x['y23'],x['x2'],x['y2'],x['x1'],x['y1']\n",
    "        p12 = np.sqrt((p1x-p2x)**2+(p1y-p2y)**2)\n",
    "        p13 = np.sqrt((p1x-p3x)**2+(p1y-p3y)**2)\n",
    "        p23 = np.sqrt((p2x-p3x)**2+(p2y-p3y)**2)\n",
    "        a = p12**2+p13**2-p23**2\n",
    "        b = 2*p12*p13\n",
    "        return np.arccos(a/b)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "#Low speed segment (<= 0.5 knots) for a time interval greater than six hours 0.5 knots = 0.000257 km/s\n",
    "def identify_low_speed_segments(mmsi_list,raw_message):\n",
    "    raw_message['TurningAngle'] = 0\n",
    "    for mmsi in mmsi_list:\n",
    "        #Find number of entries\n",
    "        entries = raw_message[raw_message['mmsi'] == mmsi]\n",
    "        entries = entries[entries.TimeStep != 0]\n",
    "        \n",
    "        #Make some temp x2,x3\n",
    "        entries = entries.join(entries['x'].shift(), lsuffix='1', rsuffix='2')\n",
    "        entries = entries.join(entries['y'].shift(), lsuffix='1', rsuffix='2')\n",
    "        \n",
    "        entries = entries.join(entries['x2'].shift(), rsuffix='3')\n",
    "        entries = entries.join(entries['y2'].shift(), rsuffix='3')\n",
    "        entries['TurningAngle'] = entries.apply(turning_angle, axis=1)\n",
    "        indicies = entries[entries['TimeStep'] > 120].index\n",
    "        \n",
    "        #Check if longer than 6 hours\n",
    "        if (entries['TimeStep'][entries.index[-1]] - entries['TimeStep'][entries.index[0]]) > 216000:\n",
    "            #Potential Low Speed Segments\n",
    "            last_ind=0\n",
    "            for each in indicies:\n",
    "                if (entries['TimeStep'][entries.index[indicies]] - entries['TimeStep'][entries.index[last_ind]]) > 216000:\n",
    "                    if entries['Velocity'].iloc[last_ind:indicies].mean() < 0.000257:\n",
    "                        raw_message.ix[last_ind:indicies, 'BadData'] = 1\n",
    "                last_ind = each+1\n",
    "                \n",
    "        raw_message.ix[raw_message['mmsi'] == mmsi, 'TurningAngle'] = entries['TurningAngle']\n",
    "        \n",
    "    return raw_message\n",
    "\n",
    "mmsi_test = test_raw_message['mmsi'].drop_duplicates().tolist()\n",
    "mmsi_train = train_raw_message['mmsi'].drop_duplicates().tolist()\n",
    "\n",
    "train_raw_message = identify_low_speed_segments(mmsi_train,train_raw_message)\n",
    "test_raw_message = identify_low_speed_segments(mmsi_test,test_raw_message)\n",
    "\n",
    "#Replace Fishing=1, Not Fishing=0, Unknown = np.nan\n",
    "train_raw_message['Fishing'] = np.nan\n",
    "train_raw_message['Fishing'][train_raw_message['FISHING_STATUS'] == 'Fishing'] = 1\n",
    "train_raw_message['Fishing'][train_raw_message['FISHING_STATUS'] == 'Not Fishing'] = 0\n",
    "train_raw_message['Fishing'][train_raw_message['FISHING_STATUS'] == 'Unknown'] = np.nan\n",
    "\n",
    "#Clear memory\n",
    "# del test_raw_message\n",
    "# del train_raw_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/numpy/lib/function_base.py:3823: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    134671.000000\n",
       "mean          0.400851\n",
       "std           0.490073\n",
       "min           0.000000\n",
       "25%                NaN\n",
       "50%                NaN\n",
       "75%                NaN\n",
       "max           1.000000\n",
       "Name: Fishing, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw_message['Fishing'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_GMM_data = train_raw_message[['Acceleration','Fishing','mmsi','Velocity','TurningAngle','TimeStep']][train_raw_message['BadData'] == 0]\n",
    "test_GMM_data = test_raw_message[['mmsi','Velocity','TurningAngle','TimeStep']][test_raw_message['BadData'] == 0]\n",
    "# train_raw_message[['mmsi','x','y','Velocity','TurningAngle']]\n",
    "#Sanatize for Clusters\n",
    "train_GMM_data.fillna(value=0,inplace=True)\n",
    "test_GMM_data.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#Check that the histogram distribution is similar to literature for speed\n",
    "# What does it look like for turning radius.\n",
    "i,good_mmsi_train = 0,[]\n",
    "for each in mmsi_train:\n",
    "    if len(train_raw_message[(train_raw_message['mmsi'] == each)&(train_raw_message['BadData'] == 0)]) > 100:\n",
    "        good_mmsi_train.append(each)\n",
    "        if len(train_raw_message[(train_raw_message['mmsi'] == each)&(train_raw_message['BadData'] == 0)&(train_raw_message['Fishing'] == 1)]):\n",
    "            print(i,each)\n",
    "        i+=1\n",
    "print('good',i)\n",
    "# mmsi = mmsi_train[20]\n",
    "# i=0\n",
    "each=good_mmsi_train[110]\n",
    "train_raw_message['Velocity'][(train_raw_message['mmsi'] == each)].hist(range=[0, 0.015])\n",
    "\n",
    "# train_GMM_data.hist()\n",
    "print(len(mmsi_train),len(mmsi_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d5929d290>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhUCSZpyFQJJm3P8HF5ht1BH/dukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d59294390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "each=good_mmsi_train[57]\n",
    "train_raw_message['Fishing'][(train_raw_message['mmsi'] == each)].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Guassian Mixture Model](https://github.com/cpueschel/FishingForFishermen/blob/master/Capture9.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112998, 142533)\n"
     ]
    }
   ],
   "source": [
    "# for i in range(1,17):\n",
    "#     print('\\'STD_MD_'+str(i)+'\\','),\n",
    "# 'Time_Regime_1'\n",
    "# 'Mean_Duration_1'\n",
    "# 'STD_MD_1'\n",
    "train_raw_message.columns\n",
    "\n",
    "len(train_raw_message['nav_status'][train_raw_message['nav_status']==1])#.describe()\n",
    "print(len(train_GMM_data),len(train_raw_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#GMM, purpose, join the distribution of speed and turning angle.\n",
    "#Good resource: http://stackoverflow.com/questions/26019584/understanding-concept-of-gaussian-mixture-models?rq=1\n",
    "#http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GMM.html#sklearn.mixture.GMM\n",
    "K = 16             # number of mixtures/clusters\n",
    "random_state = 170\n",
    "train_kmeans = []\n",
    "# for K in range(1,17):\n",
    "score,aic,ii = 0,0,0\n",
    "\n",
    "#Prep\n",
    "cols = ['Mean_Lat','Mean_Long','Std_Lat','Std_Long','Sinuosity','Regime','Time_Regime_1', 'Time_Regime_2', 'Time_Regime_3', 'Time_Regime_4', 'Time_Regime_5', 'Time_Regime_6', 'Time_Regime_7', 'Time_Regime_8', 'Time_Regime_9', 'Time_Regime_10', 'Time_Regime_11', 'Time_Regime_12', 'Time_Regime_13', 'Time_Regime_14', 'Time_Regime_15', 'Time_Regime_16','Mean_Duration_1', 'Mean_Duration_2', 'Mean_Duration_3', 'Mean_Duration_4', 'Mean_Duration_5', 'Mean_Duration_6', 'Mean_Duration_7', 'Mean_Duration_8', 'Mean_Duration_9', 'Mean_Duration_10', 'Mean_Duration_11', 'Mean_Duration_12', 'Mean_Duration_13', 'Mean_Duration_14', 'Mean_Duration_15', 'Mean_Duration_16','STD_MD_1', 'STD_MD_2', 'STD_MD_3', 'STD_MD_4', 'STD_MD_5', 'STD_MD_6', 'STD_MD_7', 'STD_MD_8', 'STD_MD_9', 'STD_MD_10', 'STD_MD_11', 'STD_MD_12', 'STD_MD_13', 'STD_MD_14', 'STD_MD_15', 'STD_MD_16']\n",
    "regime = ['Time_Regime_1', 'Time_Regime_2', 'Time_Regime_3', 'Time_Regime_4', 'Time_Regime_5', 'Time_Regime_6', 'Time_Regime_7', 'Time_Regime_8', 'Time_Regime_9', 'Time_Regime_10', 'Time_Regime_11', 'Time_Regime_12', 'Time_Regime_13', 'Time_Regime_14', 'Time_Regime_15', 'Time_Regime_16']\n",
    "meand=['Mean_Duration_1', 'Mean_Duration_2', 'Mean_Duration_3', 'Mean_Duration_4', 'Mean_Duration_5', 'Mean_Duration_6', 'Mean_Duration_7', 'Mean_Duration_8', 'Mean_Duration_9', 'Mean_Duration_10', 'Mean_Duration_11', 'Mean_Duration_12', 'Mean_Duration_13', 'Mean_Duration_14', 'Mean_Duration_15', 'Mean_Duration_16']\n",
    "std =['STD_MD_1', 'STD_MD_2', 'STD_MD_3', 'STD_MD_4', 'STD_MD_5', 'STD_MD_6', 'STD_MD_7', 'STD_MD_8', 'STD_MD_9', 'STD_MD_10', 'STD_MD_11', 'STD_MD_12', 'STD_MD_13', 'STD_MD_14', 'STD_MD_15', 'STD_MD_16']\n",
    "\n",
    "def time_regime(x):\n",
    "    x[regime[int(x['Regime'])-1]]=x['Regime']*x['TimeStep']\n",
    "    return x\n",
    "\n",
    "def mean_duration(x):\n",
    "    for i in range(0,16):\n",
    "        x[meand[i]]=x[regime[i]].mean()\n",
    "    return x\n",
    "\n",
    "def std_Mean_duration(x):\n",
    "    for i in range(0,16):\n",
    "        x[std[i]]=x[regime[i]].std()\n",
    "    return x\n",
    "\n",
    "for each in cols:\n",
    "    test_raw_message[each],train_raw_message[each] = 0,0\n",
    "\n",
    "    #Sinuosity\n",
    "def calc_sinuosity(x):\n",
    "    #SI = along stream/ between two points\n",
    "    #Split into segments, if TimeStep is too Large (>3 hours)\n",
    "    def haversines(x):#lon1, lat1, lon2, lat2):\n",
    "        # decimal degrees to radian\n",
    "#         print(x['x'].iloc[-1], x['y'].iloc[-1])\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [x['x'].iloc[0], x['y'].iloc[0], x['x'].iloc[-1], x['y'].iloc[-1]])\n",
    "        # haversine formula \n",
    "        dlon = lon2 - lon1 \n",
    "        dlat = lat2 - lat1 \n",
    "        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "        c = 2 * np.arcsin(np.sqrt(a)) \n",
    "        r = 6371 # Radius of earth in kilometers\n",
    "        return c * r\n",
    "    length = haversines(x)\n",
    "    sum_dist = x['Haversine'].sum()\n",
    "    x['Sinuosity'] = sum_dist/length\n",
    "    return x\n",
    "\n",
    "def Position_Information(x):\n",
    "    vals= pd.DataFrame()\n",
    "    vals = x[['x','y']].dropna()\n",
    "    x['Mean_Lat'] = vals['x'].mean()\n",
    "    x['Std_Lat'] = vals['x'].std()\n",
    "    \n",
    "    x['Mean_Long'] = vals['y'].mean()\n",
    "    x['Std_Long'] = vals['y'].std()   \n",
    "    return x\n",
    "\n",
    "# TRAIN\n",
    "train_raw_message['Velocity'] = train_raw_message['Velocity']*10\n",
    "train_raw_message['Acceleration'] = train_raw_message['Acceleration']*10\n",
    "\n",
    "test_raw_message['Velocity'] = test_raw_message['Velocity']*10\n",
    "test_raw_message['Acceleration'] = test_raw_message['Acceleration']*10\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for ship in mmsi_train:\n",
    "#     i+=1\n",
    "    if (len(train_raw_message[train_raw_message['mmsi']==ship]) > K):\n",
    "        ii+=1\n",
    "        data = train_raw_message[['Velocity','TurningAngle']][train_raw_message['mmsi']==ship].fillna(value=0).values\n",
    "        \n",
    "        #Fit a GMM Model\n",
    "        clf = mixture.GMM(n_components=K, covariance_type='tied')\n",
    "        clf.fit(data)#,y=train_GMM_data[['Fishing']][train_GMM_data['mmsi']==ship].values)\n",
    "\n",
    "#         display predicted scores by the model as a contour plot\n",
    "        colors = ['r' if i==0 else 'g' for i in train_raw_message['Fishing'][train_raw_message['mmsi']==ship]]#train_GMM_data['Fishing'][train_GMM_data['mmsi']==ship]        ax = plt.gca()\n",
    "        plt.scatter(data[:,0], data[:,1], c=colors, alpha=0.8)\n",
    "        predicted=clf.predict(data)\n",
    "        \n",
    "        colors = ['r' if i==0 else 'g' for i in predicted]\n",
    "        plt.scatter(data[:,0], data[:,1], c=colors, alpha=0.8)\n",
    "        score += clf.score(data,y=train_raw_message[['Fishing']][train_raw_message['mmsi']==ship].values).mean()\n",
    "        aic+=clf.aic(data)\n",
    "        print(clf.converged_,clf.aic(data),clf.score(data,y=train_raw_message[['Fishing']][train_raw_message['mmsi']==ship].values).mean())\n",
    "        \n",
    "        train_raw_message['Regime'][train_raw_message['mmsi']==ship] = predicted\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=train_raw_message[train_raw_message['mmsi']==ship].apply(time_regime, axis=1)\n",
    "        \n",
    "        train_raw_message[train_raw_message['mmsi']==ship] = mean_duration(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        train_raw_message[train_raw_message['mmsi']==ship] = std_Mean_duration(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        \n",
    "        #Sinuosity\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=calc_sinuosity(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=Position_Information(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        plt.show()\n",
    "    else:\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=train_raw_message[train_raw_message['mmsi']==ship].apply(time_regime, axis=1)\n",
    "        train_raw_message[train_raw_message['mmsi']==ship] = mean_duration(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        train_raw_message[train_raw_message['mmsi']==ship] = std_Mean_duration(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=calc_sinuosity(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "        train_raw_message[train_raw_message['mmsi']==ship]=Position_Information(train_raw_message[train_raw_message['mmsi']==ship])\n",
    "# print('K:',K,'Score:',score/ii,'AIC:',aic/ii)\n",
    "\n",
    "#TEST\n",
    "for ship in mmsi_test:\n",
    "    break\n",
    "    if (len(test_raw_message[test_raw_message['mmsi']==test_raw_message]) > K):\n",
    "        data = test_raw_message[['Velocity','TurningAngle']][test_raw_message['mmsi']==ship].fillna(value=0).values\n",
    "        \n",
    "        #Fit a GMM Model\n",
    "        clf = mixture.GMM(n_components=K, covariance_type='tied')\n",
    "        clf.fit(data)\n",
    "\n",
    "        predicted=clf.predict(data)\n",
    "        test_raw_message['Regime'][test_raw_message['mmsi']==ship] = predicted\n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=test_raw_message[test_raw_message['mmsi']==ship].apply(time_regime, axis=1)\n",
    "        \n",
    "        test_raw_message[test_raw_message['mmsi']==ship] = mean_duration(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "        test_raw_message[test_raw_message['mmsi']==ship] = std_Mean_duration(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=calc_sinuosity(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=Position_Information(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "    else:\n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=test_raw_message[test_raw_message['mmsi']==ship].apply(time_regime, axis=1)\n",
    "        test_raw_message[test_raw_message['mmsi']==ship] = mean_duration(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "        test_raw_message[test_raw_message['mmsi']==ship] = std_Mean_duration(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=calc_sinuosity(test_raw_message[test_raw_message['mmsi']==ship])        \n",
    "        test_raw_message[test_raw_message['mmsi']==ship]=Position_Information(test_raw_message[test_raw_message['mmsi']==ship])\n",
    "\n",
    "#Choose 16 tied for now. \n",
    "# Also try K=3 and diag, and K=2 Full\n",
    "#diag\n",
    "# ('K:', 1, 'Score:', 2.8371909016198971, 'AIC:', -705.43350580700303)\n",
    "# ('K:', 2, 'Score:', 3.1546573313254176, 'AIC:', -939.9815488149203)\n",
    "# ('K:', 3, 'Score:', 3.1276335573481586, 'AIC:', -957.89544641646455) best\n",
    "# ('K:', 4, 'Score:', 3.058191457738705, 'AIC:', -957.50173747675979)\n",
    "# ('K:', 5, 'Score:', 3.0191085903250254, 'AIC:', -953.50607768443456)\n",
    "# ('K:', 6, 'Score:', 2.9844417178660554, 'AIC:', -946.76300502875108)\n",
    "# ('K:', 7, 'Score:', 2.9649568959036134, 'AIC:', -940.73787089998314)\n",
    "# ('K:', 8, 'Score:', 2.9121302373663034, 'AIC:', -934.9104654529657)\n",
    "# ('K:', 9, 'Score:', 2.8584745725770353, 'AIC:', -928.64779538735388)\n",
    "# ('K:', 10, 'Score:', 2.812622906557579, 'AIC:', -922.81699720509573)\n",
    "# ('K:', 11, 'Score:', 2.7641006858410408, 'AIC:', -916.95236653981601)\n",
    "# ('K:', 12, 'Score:', 2.7443181792654827, 'AIC:', -911.11344980948161)\n",
    "# ('K:', 13, 'Score:', 2.7192611108480871, 'AIC:', -905.20771603177786)\n",
    "# ('K:', 14, 'Score:', 2.6996741523283512, 'AIC:', -899.52362343516495)\n",
    "# ('K:', 15, 'Score:', 2.6643029425464904, 'AIC:', -893.7955449770692)\n",
    "# ('K:', 16, 'Score:', 2.6244446385944937, 'AIC:', -888.16220400218901)\n",
    "\n",
    "#full\n",
    "# ('K:', 1, 'Score:', 2.8372221650302523, 'AIC:', -704.0719413824304)\n",
    "# ('K:', 2, 'Score:', 3.1546557953556218, 'AIC:', -937.25621845611329)\n",
    "# ('K:', 3, 'Score:', 3.127559197645668, 'AIC:', -953.84186167038115) best\n",
    "# ('K:', 4, 'Score:', 3.0582485059589022, 'AIC:', -952.26719056799402)\n",
    "# ('K:', 5, 'Score:', 3.0191320667681296, 'AIC:', -947.0483370549066)\n",
    "# ('K:', 6, 'Score:', 2.9844761407165272, 'AIC:', -939.06887398782635)\n",
    "# ('K:', 7, 'Score:', 2.9649668787858343, 'AIC:', -931.84029898836275)\n",
    "# ('K:', 8, 'Score:', 2.9121705794746569, 'AIC:', -924.94226751778319)\n",
    "# ('K:', 9, 'Score:', 2.8585156498393838, 'AIC:', -917.64816479864476)\n",
    "# ('K:', 10, 'Score:', 2.8126532743814154, 'AIC:', -910.78974151699401)\n",
    "# ('K:', 11, 'Score:', 2.7641539612532124, 'AIC:', -903.93389935938853)\n",
    "# ('K:', 12, 'Score:', 2.7443541867617931, 'AIC:', -896.97240595034384)\n",
    "# ('K:', 13, 'Score:', 2.7192676697690685, 'AIC:', -890.03452833617587)\n",
    "# ('K:', 14, 'Score:', 2.6996913955387387, 'AIC:', -883.28712312458811)\n",
    "# ('K:', 15, 'Score:', 2.6643098225071657, 'AIC:', -876.60426432315137)\n",
    "# ('K:', 16, 'Score:', 2.6244718400426934, 'AIC:', -870.12265830909837)\n",
    "\n",
    "#spherical\n",
    "# ('K:', 1, 'Score:', 2.4304981314885064, 'AIC:', -377.60954956329698)\n",
    "# ('K:', 2, 'Score:', 3.0516447617072289, 'AIC:', -860.17518428666392)\n",
    "# ('K:', 3, 'Score:', 3.0676555044507352, 'AIC:', -908.06741656766599)\n",
    "# ('K:', 4, 'Score:', 3.0183463568908269, 'AIC:', -920.49045918006004)\n",
    "# ('K:', 5, 'Score:', 2.9900374232671552, 'AIC:', -925.4295532452702)\n",
    "# ('K:', 6, 'Score:', 2.9612962382565087, 'AIC:', -926.64490500004604) best\n",
    "# ('K:', 7, 'Score:', 2.9443971914913445, 'AIC:', -924.45315416083702)\n",
    "# ('K:', 8, 'Score:', 2.8933065743924882, 'AIC:', -919.81237386788519)\n",
    "# ('K:', 9, 'Score:', 2.8423936741907134, 'AIC:', -918.51531295409916)\n",
    "# ('K:', 10, 'Score:', 2.797254499859708, 'AIC:', -914.55095417953805)\n",
    "# ('K:', 11, 'Score:', 2.7487595695632692, 'AIC:', -910.52046289758846)\n",
    "# ('K:', 12, 'Score:', 2.7298566765403174, 'AIC:', -907.2970440579727)\n",
    "# ('K:', 13, 'Score:', 2.7055904341431964, 'AIC:', -903.09278147172074)\n",
    "# ('K:', 14, 'Score:', 2.6868272580661325, 'AIC:', -899.31902046141863)\n",
    "# ('K:', 15, 'Score:', 2.6517407694426729, 'AIC:', -895.05010274179688)\n",
    "# ('K:', 16, 'Score:', 2.6124000251009138, 'AIC:', -890.68557576115757)\n",
    "\n",
    "#tied\n",
    "# ('K:', 1, 'Score:', 2.8372221650302523, 'AIC:', -704.0719413824304)\n",
    "# ('K:', 2, 'Score:', 3.0531172572451855, 'AIC:', -820.47477110384511)\n",
    "# ('K:', 3, 'Score:', 3.0402780586465021, 'AIC:', -864.18337186082067)\n",
    "# ('K:', 4, 'Score:', 2.977567828395761, 'AIC:', -869.3809397574405)\n",
    "# ('K:', 5, 'Score:', 2.9535721544418054, 'AIC:', -888.78402253899196)\n",
    "# ('K:', 6, 'Score:', 2.9267999921360306, 'AIC:', -893.97960425501901)\n",
    "# ('K:', 7, 'Score:', 2.9156745006195162, 'AIC:', -901.67242246282433)\n",
    "# ('K:', 8, 'Score:', 2.8685678621424771, 'AIC:', -903.07545570213426)\n",
    "# ('K:', 9, 'Score:', 2.8201526833186468, 'AIC:', -905.84715081373747)\n",
    "# ('K:', 10, 'Score:', 2.7780209410499355, 'AIC:', -906.05560220388452)\n",
    "# ('K:', 11, 'Score:', 2.7329249797376414, 'AIC:', -906.65559032860654)\n",
    "# ('K:', 12, 'Score:', 2.7162374185254952, 'AIC:', -907.09773538621425)  best\n",
    "# ('K:', 13, 'Score:', 2.6933555224538273, 'AIC:', -905.98655646153225)\n",
    "# ('K:', 14, 'Score:', 2.6748086579041948, 'AIC:', -905.44259276222749)\n",
    "# ('K:', 15, 'Score:', 2.641923568811686, 'AIC:', -904.83670002752831)\n",
    "# ('K:', 16, 'Score:', 2.6030241746024938, 'AIC:', -902.90499799423719)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw_message.to_pickle('train_raw_message-3-K3-diag.pkl')\n",
    "test_raw_message.to_pickle('test_raw_message-3-K3-diag.pkl')\n",
    "\n",
    "# train_raw_message[train_raw_message['Fishing'] == 0.5] = np.nan\n",
    "train_raw_message['nav_status'].describe() #may want to exapnd to more rows as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_raw_message = pd.read_pickle('train_raw_message-3.pkl')\n",
    "# test_raw_message = pd.read_pickle('test_raw_message-3.pkl')\n",
    "\n",
    "train_raw_message=pd.read_pickle('train_raw_message-3-K3-diag.pkl')\n",
    "test_raw_message=pd.read_pickle('test_raw_message-3-K3-diag.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_raw_message['Fishing'][train_raw_message['Fishing'] == np.nan].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_raw_message.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['TurningAngle','Velocity','Acceleration','Mean_Lat','Mean_Long','Std_Lat','Std_Long','Sinuosity','Regime','Time_Regime_1', 'Time_Regime_2', 'Time_Regime_3', 'Time_Regime_4', 'Time_Regime_5', 'Time_Regime_6', 'Time_Regime_7', 'Time_Regime_8', 'Time_Regime_9', 'Time_Regime_10', 'Time_Regime_11', 'Time_Regime_12', 'Time_Regime_13', 'Time_Regime_14', 'Time_Regime_15', 'Time_Regime_16','Mean_Duration_1', 'Mean_Duration_2', 'Mean_Duration_3', 'Mean_Duration_4', 'Mean_Duration_5', 'Mean_Duration_6', 'Mean_Duration_7', 'Mean_Duration_8', 'Mean_Duration_9', 'Mean_Duration_10', 'Mean_Duration_11', 'Mean_Duration_12', 'Mean_Duration_13', 'Mean_Duration_14', 'Mean_Duration_15', 'Mean_Duration_16','STD_MD_1', 'STD_MD_2', 'STD_MD_3', 'STD_MD_4', 'STD_MD_5', 'STD_MD_6', 'STD_MD_7', 'STD_MD_8', 'STD_MD_9', 'STD_MD_10', 'STD_MD_11', 'STD_MD_12', 'STD_MD_13', 'STD_MD_14', 'STD_MD_15', 'STD_MD_16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add in turning angle and veolcity?\n",
    "train_data,test_data,train_data_y,test_index = pd.DataFrame(),pd.DataFrame(),pd.DataFrame(),pd.DataFrame()\n",
    "cols.append('ShorelineDistance')\n",
    "train_data_y['Fishing']=train_raw_message['Fishing'].fillna(value=0.0)\n",
    "test_index = test_raw_message['index']\n",
    "for each in cols:\n",
    "    train_data[each] = train_raw_message[each].fillna(value=0)\n",
    "    test_data[each] = test_raw_message[each].fillna(value=0)\n",
    "    \n",
    "    train_data[each][train_raw_message[each] == np.inf] = 0\n",
    "    test_data[each][test_raw_message[each] == np.inf] = 0\n",
    "    \n",
    "# train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(train_data, train_data_y)\n",
    "print(rf.score(train_data, train_data_y))\n",
    "#0.979"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Train a XGBoost model\")\n",
    "params = {\"objective\": \"binary:logistic\",\n",
    "          \"eta\": 0.3,\n",
    "          \"max_depth\": 12,\n",
    "          #\"min_child_weight\": 0.5,\n",
    "          \"subsample\": 0.95,\n",
    "          \"colsample_bytree\": 0.8,\n",
    "          \"eval_metric\": \"auc\", #or error\n",
    "          \"gamma\": 0.0,\n",
    "          \"max_delta_step\": 1,\n",
    "          \"seed\": 420\n",
    "         }\n",
    "num_round=1000\n",
    "train_data['Fishing']=train_data_y['Fishing']\n",
    "train_data=train_data.reindex(np.random.permutation(train_data.index))\n",
    "del train_data_y\n",
    "train_data_y = pd.DataFrame()\n",
    "train_data_y = train_data['Fishing']\n",
    "train_data.drop('Fishing',axis=1,inplace=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(data=train_data,label=train_data_y, missing=np.nan)\n",
    "gbm = xgb.train(params,dtrain, num_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "# cv_res = xgb.cv(params, dtrain, num_round, nfold=5,metrics={'error'})\n",
    "\n",
    "#columns\n",
    "features_train = list(train_data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def ceate_feature_map(features):\n",
    "    outfile = open('XGBoost-Method.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "\n",
    "    outfile.close()\n",
    "features = features_train\n",
    "ceate_feature_map(features)    \n",
    "\n",
    "importance = gbm.get_fscore(fmap='XGBoost-Method.fmap')\n",
    "\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "df.plot()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(20, 30))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('relative importance')\n",
    "plt.gcf().savefig('XGBoost-Method.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, metrics\n",
    "def binary(x):\n",
    "    if x > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "asdf = gbm.predict(xgb.DMatrix(data=train_data[120000:], missing=np.nan))\n",
    "vecfunc = np.vectorize(binary)\n",
    "result = vecfunc(asdf)\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(vecfunc(train_data_y[120000:]), result))\n",
    "\n",
    "#0.97814541194\n",
    "# params = {\"objective\": \"binary:logistic\",\n",
    "#           \"eta\": 0.3,\n",
    "#           \"max_depth\": 12,\n",
    "#           #\"min_child_weight\": 0.5,\n",
    "#           \"subsample\": 0.95,\n",
    "#           \"colsample_bytree\": 0.8,\n",
    "#           \"eval_metric\": \"error\", #or error\n",
    "#           \"gamma\": 0.0,\n",
    "#           \"max_delta_step\": 1,\n",
    "#           \"seed\": 420\n",
    "#          }\n",
    "# num_round=1000\n",
    "\n",
    "#K=3 diag\n",
    "#0.83539 no shuffle\n",
    "#0.9594 with shuffle cols = ['TurningAngle','Velocity','Acceleration','Mean_Lat','Mean_Long','Std_Lat','Std_Long','Sinuosity','Regime','Time_Regime_1', 'Time_Regime_2', 'Time_Regime_3', 'Time_Regime_4', 'Time_Regime_5', 'Time_Regime_6', 'Time_Regime_7', 'Time_Regime_8', 'Time_Regime_9', 'Time_Regime_10', 'Time_Regime_11', 'Time_Regime_12', 'Time_Regime_13', 'Time_Regime_14', 'Time_Regime_15', 'Time_Regime_16','Mean_Duration_1', 'Mean_Duration_2', 'Mean_Duration_3', 'Mean_Duration_4', 'Mean_Duration_5', 'Mean_Duration_6', 'Mean_Duration_7', 'Mean_Duration_8', 'Mean_Duration_9', 'Mean_Duration_10', 'Mean_Duration_11', 'Mean_Duration_12', 'Mean_Duration_13', 'Mean_Duration_14', 'Mean_Duration_15', 'Mean_Duration_16','STD_MD_1', 'STD_MD_2', 'STD_MD_3', 'STD_MD_4', 'STD_MD_5', 'STD_MD_6', 'STD_MD_7', 'STD_MD_8', 'STD_MD_9', 'STD_MD_10', 'STD_MD_11', 'STD_MD_12', 'STD_MD_13', 'STD_MD_14', 'STD_MD_15', 'STD_MD_16']\n",
    "#0.956552611725 without 'TimeStep'\n",
    "# 0.958505303333 without 'status'\n",
    "# without timestep, status, and 'Acceleration'\n",
    "\n",
    "#K=16 tied\n",
    "# 0.958594062042 error\n",
    "# 0.96014 trained with auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(train_data_y[120000:], asdf, pos_label=1)\n",
    "auc = metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "auc, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save-the-results\n",
    "#Each line should contain only one human readable number between 0 and 1 indicating the fishing confidence for the corresponding message.\n",
    "#It would be a good idea to test between [0,1] and the post processed 0 or 1\n",
    "dftest=xgb.DMatrix(data=test_data, missing=np.nan)\n",
    "results=gbm.predict(dftest)\n",
    "\n",
    "#Sort to prior\n",
    "results_sorted = pd.DataFrame()\n",
    "results_sorted['true_index'] = test_raw_message['index']\n",
    "results_sorted['results'] = results\n",
    "results_sorted.sort('true_index',inplace=True)\n",
    "\n",
    "#Save in proper format!\n",
    "output = pd.DataFrame({'results': results_sorted['results']})\n",
    "output.to_csv('FR-K3-tied-train-percent-0.958372165269.csv',index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
